### 个人基本信息
1. 姓名：陈兴平（最好写Xingping Chen）或英文名legend
2. 职业：学生，就读于中山大学计算机学院
3. 邮箱：chenxp68@mail2.sysu.edu.cn
4. 个人简介：
   - 目前就读于中山大学计算机学院，专业是信息与计算数学
   - 喜欢探索新技术，热衷于关注最新的技术动态
   - 对量子计算、CV、LLM等领域有浓厚的兴趣
   - 现在正在入门具身智能领域，欢迎与我交流

### 技能与专业领域
1. 技术技能
   - 编程语言：python、cpp
   - AI框架：pytorch
2. 专业（以及兴趣）领域
   - 具身智能（VLA）
   - 量子计算
   - 计算机视觉
   - 大语言模型

### 项目展示
暂无

### 网页模块偏好
希望包含的模块：
- 个人介绍/关于我
- 技能展示
- 作品/项目罗列（论文、项目等，暂时先随便填写示例内容）
- 项目展示（可以暂时先随便填充示例内容）
- 碎碎念（主要展示个人对一些方向的理解和随想）

### 碎碎念
#### （1）关于研究方向
个人规划
本人对自己的本科期间规划是通专融合，未来重科研且倾向于读博。
·通：在打好专业基础的同时，向自己感兴趣的多个方向进行探索，并最终收敛到一个自己最感兴趣且最有想法的领域，并在这一领域中完成自己的毕业设计。在已经过去的大一到大三，我密切关注着计算机的前沿发展，探索了oi算法、CTF（安全）、人工智能、爬虫、量子计算等多个计算机领域。
·专：在这些尝试中，我取得了一些小小的成果，也遇到了不少挫折。在经过不断的尝试和充分的思考后，我现在对计算机视觉与其它模态的交互有着浓厚的兴趣，认为这是让具身智能发展和最终落地的重要一环。因此，我希望能投身于相关的科研实践中去。
**对现在研究方向(VLA)的理解和研究动机：**
在我整个大学阶段，人工智能领域经历了关键的技术跃迁。自GPT3发布以来，我密切关注大模型从兴起、演进到广泛落地的全过程。我见证了大模型通过强化学习获得推理能力，实现对复杂情境的深入思考；也观察到RAG、智能体工作流及MCP等技术的实际应用，推动大语言模型(LLM)的功能日益接近人类认知水平。
与此同时，机器人技术也在近年来取得显著突破。从宇树科技发布的自主平衡行走机器人，到WAIC、机器人运动会等展会中展示出的先进运动控制能力，都表明机器人的运动中枢相当于人类的小脑与神经运动系统一正在快速发展。这一切似乎预示着，我们正逐步接近具身智能的实用化阶段。
然而我注意到，当前技术仍存在一个关键短板：机器人尚未具备人类式的多模态环境感知与物理交互能力。尽管已有不少公司通过对齐视觉-语言模态，训练出具有一定视觉理解能力的VLM(Vision-Language Model),，但仅实现视觉层面的“理解”还远远不够。真正的具身智能需融合视觉信息与人类指令，做出精准目可泛化的物理动作(Visua-Language-Action,VLA),从而在现实世界中实现理解和交互。
因此，我渴望投身于这一领域的科研与实践，致力于为机器人构建更强大的“眼睛”，使其能够真正感知并理解物理环境，同时通过机械臂、夹爪或灵巧手等执行机构，实现与世界的深层、有效互动。

#### 关于具身智能


#### 关于LLM及其应用

#### 关于量子计算

#### 其它领域